{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment_wall_street_bert.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wojpMOPmQ29"
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9ASv0PU2A5B"
      },
      "source": [
        "pip install raceplotly"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3ZDUgwzvJWO"
      },
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "from datetime import date\n",
        "import calendar\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "import matplotlib.pyplot as plt\n",
        "from raceplotly.plots import barplot\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "tokenizer = AutoTokenizer.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')\n",
        "model = AutoModelForSequenceClassification.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zooihWJyvLjU"
      },
      "source": [
        "data=pd.read_csv('/content/reddit_wsb.csv')\n",
        "#uncomend the line below if you are facing out of RAM issue, just to see how the code works\n",
        "#data=data.iloc[0:2500]\n",
        "#converting the timestamp column in our data to date time format, which will makes us to perform better analysis\n",
        "data[['timestamp']] = data[['timestamp']].apply(pd.to_datetime)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqSUCFZkHPXn",
        "outputId": "a1ed6a9e-b16b-4991-e968-59567361e95d"
      },
      "source": [
        "data.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 48260 entries, 0 to 48259\n",
            "Data columns (total 8 columns):\n",
            " #   Column     Non-Null Count  Dtype         \n",
            "---  ------     --------------  -----         \n",
            " 0   title      48260 non-null  object        \n",
            " 1   score      48260 non-null  int64         \n",
            " 2   id         48260 non-null  object        \n",
            " 3   url        48260 non-null  object        \n",
            " 4   comms_num  48260 non-null  int64         \n",
            " 5   created    48260 non-null  float64       \n",
            " 6   body       22521 non-null  object        \n",
            " 7   timestamp  48260 non-null  datetime64[ns]\n",
            "dtypes: datetime64[ns](1), float64(1), int64(2), object(4)\n",
            "memory usage: 2.9+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nr3hQ2FDG-Ec"
      },
      "source": [
        "\n",
        "*   Replacing nan values with blank space, because we will be merging title column and body column so that we get broader range of words to get the perfect accuracy and the 'body' column contains many nan values. Which can be figured out by after running previous cell. Wherein, body column contains only 22521 non-null values remaning all are nan values.\n",
        "nan values contribute to 52.33% of total values in body column. \n",
        "\n",
        "*   dropping 'score','id' and 'created' column as they do not serve any purpose in determining the sentiments\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rO-vV1m7H1cN"
      },
      "source": [
        "data = data.replace(np.nan, '', regex=True)\n",
        "data.drop(['score','id','created'],axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NC-dkxj7Kidy"
      },
      "source": [
        "Getting the total number of words in 'title' column foro each record"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppH1H8jDvYke"
      },
      "source": [
        "data['length']=data['title'].apply(lambda x : len(x.split(' ')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5OlwqlkKsxM"
      },
      "source": [
        "Creating a function 'weekdy' to get the weekdays from timestamp column on which the post has been posted"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1X4awQOw1Zjk"
      },
      "source": [
        "def weekdy(x):\n",
        "    my_date = x\n",
        "    return calendar.day_name[my_date.weekday()]\n",
        "data['weekdays']=data['timestamp'].apply(lambda x : weekdy(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbun508y_kGF"
      },
      "source": [
        "**What is the distribution of title length in the data??**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6uoUt711bVb"
      },
      "source": [
        "px.histogram(data,x='length',template='seaborn')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fn-kCrb2_7fT"
      },
      "source": [
        "Most of the posts are of length that lies between 0-20 . Why is it like that , well title's are kept short to just give you of a gist of what lies in the body so it doesn't need to be too long :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdPtUqCUBejx"
      },
      "source": [
        "**Post Distribution In Reddit according to days in a Week In Wall Street**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0qJiXzU1dBP"
      },
      "source": [
        "px.histogram(data,x='weekdays',color='weekdays',template='seaborn')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FedZyukK7GZ"
      },
      "source": [
        "Preprocessing a given text before feeding into model is always a good practice, because our texts include many emoticons, urls, websites, hashtags which don't contribute to sentiment analysis.\n",
        "\n",
        "*   The 'preprocess' function will remove everything apart from alphabets\n",
        "from our texts\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eK93aXwQ9XOW"
      },
      "source": [
        "def preprocess(text):\n",
        "    processed_text = re.sub('[^a-zA-Z]',' ',text)\n",
        "    return processed_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daP2a8C8Lf1Y"
      },
      "source": [
        "\n",
        "\n",
        "*   Merging \"title\" and \"body\" as said before for better accuracy and storing them into a column named \"full text\".\n",
        "*   Limiting our total value of words in each text to 500, in order to reduce computational time and storing them in a column named \"limited text\".\n",
        "*   Passing the limited texts to preprocess function to get the processed texts which can be fed to our model and storing them in the column named \"processed_text\"\n",
        "*   Now, dropping \"full text\" and \"limited text\" columns as they serve no further purpose\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5F0S6VXT1x21"
      },
      "source": [
        "data['full text']=data.title+\" \"+data['body'].astype(\"str\")\n",
        "data['limited text']=data['full text'].apply(lambda x : x[0:500])\n",
        "data['processed_text']=data['limited text'].apply(lambda x : preprocess(x))\n",
        "data.drop(['full text','limited text'], axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5WxHhGYMnoE"
      },
      "source": [
        "Any model can't understand alphabets as input, it only understands numericals. So we have to convert each and every letter to numbers before feeding into model. Tokenizer is the library which can fulfill this task.\n",
        "\n",
        "\n",
        "*   Created a list with the name \"tok\" which will be having numerical form of text from each record\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vWhVTHY1_d1"
      },
      "source": [
        "tok=[]\n",
        "for texts in  data['processed_text']:\n",
        "  tokens = tokenizer.encode(texts, return_tensors='pt')\n",
        "  tok.append(tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_t8TE58NRib"
      },
      "source": [
        "Our model predicts emotion of a given statement by computing 5 unique values. The maximum value's position gives us the sentiment.\n",
        "\n",
        "*   highest value is in 1st place - highly negative statement\n",
        "*   highest value is in 2nd place - negative statement\n",
        "*   highest value is in 3rd place - neutral statement\n",
        "*   highest value is in 4th place - positive statement\n",
        "*   highest value is in 5th place - highly positive statement\n",
        "\n",
        "\"result\" list will be having these information for each records text\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EM-Zifw2H2t"
      },
      "source": [
        "result=[]\n",
        "for i in range(len(tok)):\n",
        "  res=model(tok[i])\n",
        "  result.append(res)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVLvkc7ROUi9"
      },
      "source": [
        "Creating columns with names \"most neagtive\", \"negative\", \"neutral\", \"positive\", \"most positive\" in our data frame and adding the sentiment values beneath them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiCQEfAP5c0B"
      },
      "source": [
        "x=[]\n",
        "x1=[]\n",
        "x2=[]\n",
        "x3=[]\n",
        "x4=[]\n",
        "x5=[]\n",
        "for i in range(len(result)):\n",
        "  val=result[i].logits[0]\n",
        "  for values in val:\n",
        "    x.append(float(values))\n",
        "\n",
        "for i in range(0,len(x),5):\n",
        "  x1.append(x[i])\n",
        "for i in range(1,len(x),5):\n",
        "  x2.append(x[i])\n",
        "for i in range(2,len(x),5):\n",
        "  x3.append(x[i])\n",
        "for i in range(3,len(x),5):\n",
        "  x4.append(x[i])\n",
        "for i in range(4,len(x),5):\n",
        "  x5.append(x[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHmthAZPV5b3"
      },
      "source": [
        "data['MOST NEGATIVE']=x1\n",
        "data['NEGATIVE']=x2\n",
        "data['NEUTRAL']=x3\n",
        "data['POSITIVE']=x4\n",
        "data['MOST POSITIVE']=x5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoJCpvEKOp34"
      },
      "source": [
        "Now, getting the most dominant sentiment among all five columns and storing it in \"DOMINANT\" column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7BCtZxSqrkp"
      },
      "source": [
        "data=data.reset_index()\n",
        "data['DOMINANT']=data[['MOST NEGATIVE','NEGATIVE','NEUTRAL','POSITIVE','MOST POSITIVE']].idxmax(axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtuPFh-XDw_V"
      },
      "source": [
        "**Relationship between Emotion and texts**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzuHq6xECLu9"
      },
      "source": [
        "px.histogram(data,x='DOMINANT',template='seaborn')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guAU0-SNCUFO"
      },
      "source": [
        "**Relationship between Emotion and Number of comments**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEExB4g6u0J2"
      },
      "source": [
        "rel=data.groupby('DOMINANT').sum()\n",
        "px.bar(x=rel.index,y=rel['comms_num'].values,template='seaborn',labels={'x':'Emotion','y':'Number of comments'})\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOrEgr7KCKxL"
      },
      "source": [
        "**10 Most Common Domains Shared In The URL Column**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNdKJWpsuiZe"
      },
      "source": [
        "text=[]\n",
        "for i in data['url']:\n",
        "    t=i\n",
        "    if '/' in t:\n",
        "        t=t.split('/')[2]\n",
        "    if 'www.' in t:\n",
        "        t=t.split('www.')[1]\n",
        "    if '.com' in t:\n",
        "        t=t.split('.com')[0]\n",
        "    text.append(t)\n",
        "text=pd.DataFrame(columns=['text'],data=text)\n",
        "s=' '\n",
        "for i in text['text'].values:\n",
        "    s+=' '+i\n",
        "text=text['text'].value_counts()\n",
        "px.bar(x=text.index[:10],y=text.values[:10],template='seaborn',labels={'x':'Domains','y':'Count'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8Z3QHafO1dN"
      },
      "source": [
        "Creating a generalised function \"sentiment_score\" which takes any sentence as input and will return you the sentiment of that sentence in terms of words. However, I have applied this function to our dataframe and again predicted the sentiment of each records."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmHdB8va5W-e"
      },
      "source": [
        "def sentiment_score(review):\n",
        "    tokens = tokenizer.encode(review, return_tensors='pt')\n",
        "    result = model(tokens)\n",
        "    value= int(torch.argmax(result.logits))+1\n",
        "    if value == 1 :\n",
        "        return \"Most Negative\"\n",
        "    elif value == 2 :\n",
        "      return 'Negative'\n",
        "    elif value == 3:\n",
        "        return \"Neutral\"\n",
        "    elif value==4:\n",
        "        return \"Positive\"\n",
        "    else:\n",
        "      return 'Most positive'\n",
        "\n",
        "    print('done')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVvwCN315Y78",
        "outputId": "70457a02-c3d6-4023-c02c-ea66584ed58c"
      },
      "source": [
        "sentiment_score('I am not sure about pizaas'),sentiment_score('I love you'),sentiment_score('I do not love you'), sentiment_score('I think I am good'),sentiment_score('This is the worst pizza ever')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Neutral', 'Most positive', 'Most Negative', 'Positive', 'Most Negative')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnU3vyny8OKC"
      },
      "source": [
        "data['sentiment']=data['processed_text'].apply(lambda x :sentiment_score(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mz-OjS-xPdAe"
      },
      "source": [
        "Saving a dataframe with only processed text and its sentiments to a csv file with name sentiment_analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "La0f10mbLcoc"
      },
      "source": [
        "df=pd.DataFrame()\n",
        "df['processed_text']=data.processed_text\n",
        "df['sentiment']=data.sentiment"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrxLWdpELphx"
      },
      "source": [
        "df.to_csv('sentiment_analysis.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_tzZ_EdNNZd",
        "outputId": "15b913b1-805c-41b6-d9e6-e3050e17e759"
      },
      "source": [
        "!sudo apt-get install git-lfs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  git-lfs\n",
            "0 upgraded, 1 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 2,129 kB of archives.\n",
            "After this operation, 7,662 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 git-lfs amd64 2.3.4-1 [2,129 kB]\n",
            "Fetched 2,129 kB in 1s (1,655 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package git-lfs.\n",
            "(Reading database ... 160772 files and directories currently installed.)\n",
            "Preparing to unpack .../git-lfs_2.3.4-1_amd64.deb ...\n",
            "Unpacking git-lfs (2.3.4-1) ...\n",
            "Setting up git-lfs (2.3.4-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGUwsAjgNNN8",
        "outputId": "27015774-5cf6-4e5f-a990-c0afd7f0cf21"
      },
      "source": [
        "!transformers-cli login"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-06-03 18:49:04.108252: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "\n",
            "        _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "        _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "        _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "        _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "        _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "        \n",
            "Username: luka89661@gmail.com\n",
            "Password: \n",
            "Login successful\n",
            "Your token: VSLXIYpMWzpFFJUHVkPSnQRoHASWXsFErLquDZrHrJOcTncPHcqrdRNGFXlpLZwLddtYHeHCEcfPiGevYziRXDQByUsKNeReZtsfsClBigqagsMUlWGfIUmyPuzlsSMG \n",
            "\n",
            "Your token has been saved to /root/.huggingface/token\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ix1J-iGLNRRx"
      },
      "source": [
        "!git config --global user.email \"luka89661@gmail.com\"\n",
        "!git config --global user.name \"orange\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrMxSk9RNY6Q"
      },
      "source": [
        "model.push_to_hub(\"sentiment_analysis\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BNPxz5YNhPA"
      },
      "source": [
        "tokenizer.push_to_hub(\"sentiment_analysis\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dc57pTzMNlCd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
